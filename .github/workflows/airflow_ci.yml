name: Airflow CI Workflow

# When to run this workflow: on every push and pull request to the main branch
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build-and-test:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout code
    - name: Checkout code
      uses: actions/checkout@v2

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'  

    # Step 3: Set up Postgres service (required for Airflow)
    - name: Setup PostgreSQL
      uses: Harmon758/postgresql-action@v1.0.0
      with:
        postgresql version: '13'
        postgresql db: 'airflow'
        postgresql user: 'airflow'
        postgresql password: 'airflow'

    # Step 4: Install dependencies (Airflow, Astro)
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install apache-airflow[postgres]==2.10.2 pandas beautifulsoup4

    # Step 5: Run airflow db initialization
    - name: Initialize Airflow DB
      run: |
        airflow db init

    # Step 6: Set up Airflow environment variables
    - name: Set environment variables
      run: |
        echo "AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost/airflow" >> $GITHUB_ENV
        echo "AIRFLOW__CORE__LOAD_EXAMPLES=False" >> $GITHUB_ENV

    # Step 7: Test DAG import (to ensure there are no import errors)
    - name: Test DAG Import
      run: |
        airflow dags list

    # Step 8: Validate the DAG (this ensures your DAG syntax is correct)
    - name: Validate DAGs
      run: |
        airflow dags validate -f dags/wikiflow.py

    # Step 9: Trigger DAG Run
    - name: Trigger DAG run
      run: |
        airflow dags trigger wikiflow
